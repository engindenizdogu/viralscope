{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylw6YSJkgxt5"
      },
      "outputs": [],
      "source": [
        "''' Dataset information\n",
        "| Data File                   | Size     | Comment                                    |\n",
        "|:----------------------------|:---------|:-------------------------------------------|\n",
        "| _raw_df_channels.tsv.gz     | 6.4 MB   | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| _raw_df_timeseries.tsv.gz   | 653.1 MB | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| _raw_yt_metadata.jsonl.zst  | 14.7 GB  | Sample dataset created.                    |\n",
        "| df_channels_en.tsv.gz       | 6.0 MB   | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| df_timeseries_en.tsv.gz     | 571.1 MB | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| num_comments.tsv.gz         | 754.6 MB | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| num_comments_authors.tsv.gz | 1.4 GB   | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| youtube_comments.tsv.gz     | 77.2 GB  | See 'create_sample_datasets_tsv.ipynb'     |\n",
        "| yt_metadata_en.jsonl.gz     | 13.6 GB  | Sample dataset created.                    |\n",
        "| yt_metadata_helper.feather  | 2.8 GB   | See 'create_sample_datasets_feather.ipynb' |\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "import io\n",
        "import zstandard as zstd\n",
        "\n",
        "# Verify current working directory\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters for both json and zst file sampling\n",
        "NUM_ITEMS = 85_000_000\n",
        "SAMPLE_SIZE = 50_000\n",
        "\n",
        "JSON_FILE_NAME = 'yt_metadata_en'\n",
        "JSON_PATH = f'../../RawData/{JSON_FILE_NAME}' + '.jsonl.gz'\n",
        "\n",
        "ZST_FILE_NAME = '_raw_yt_metadata'\n",
        "ZST_PATH = f\"../../RawData/{ZST_FILE_NAME}.jsonl.zst\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read .jsonl.gz files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read and display some records from the JSONL file\n",
        "records_json = []\n",
        "with gzip.open(JSON_PATH, 'rt', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= NUM_ITEMS:\n",
        "            break\n",
        "        records_json.append(json.loads(line))\n",
        "\n",
        "print(f\"Read {len(records_json)} items from {JSON_PATH}\")\n",
        "print(\"\\nExample record:\")\n",
        "print(json.dumps(records_json[0], indent=2))\n",
        "print(\"\\nSample of 5 records:\")\n",
        "for record in records_json[:5]:\n",
        "    print(record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Randomly sample 50,000 records into a pandas DataFrame\n",
        "sample_records = random.sample(records_json, SAMPLE_SIZE)\n",
        "df_sample_json = pd.DataFrame(sample_records)\n",
        "print(f\"Sampled dataset shape: {df_sample_json.shape}\")\n",
        "df_sample_json.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write to .csv file\n",
        "df_sample_json.to_csv(f'../SampleData/{JSON_FILE_NAME}' + '_sample.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read .jsonl.zst files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stream-read .jsonl.zst, sample 50k, create DataFrame and save\n",
        "records_zst = []\n",
        "print(f\"Reading up to {NUM_ITEMS:,} lines from {ZST_PATH}\")\n",
        "with open(ZST_PATH, 'rb') as fh:\n",
        "    dctx = zstd.ZstdDecompressor()\n",
        "    with dctx.stream_reader(fh) as reader:\n",
        "        text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n",
        "        for i, line in enumerate(text_stream):\n",
        "            if i >= NUM_ITEMS:\n",
        "                break\n",
        "            records_zst.append(json.loads(line))\n",
        "\n",
        "print(f\"Total records read: {len(records_zst):,}\")\n",
        "print(\"Example record (first):\")\n",
        "print(json.dumps(records_zst[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random sample\n",
        "sample_zst_records = random.sample(records_zst, SAMPLE_SIZE)\n",
        "df_sample_zst = pd.DataFrame(sample_zst_records)\n",
        "print(f\"Sampled DataFrame shape: {df_sample_zst.shape}\")\n",
        "df_sample_zst.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write to .csv file\n",
        "output_path = f\"../SampleData/{ZST_FILE_NAME}_sample.csv\"\n",
        "df_sample_zst.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(f\"../SampleData/{JSON_FILE_NAME}_sample.csv\")\n",
        "df2 = pd.read_csv(f\"../SampleData/{ZST_FILE_NAME}_sample.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df1.shape)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df2.shape)\n",
        "df2.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "stevens",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
